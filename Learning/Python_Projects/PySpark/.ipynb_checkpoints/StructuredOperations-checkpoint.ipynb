{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-inspiration",
   "metadata": {},
   "source": [
    "# Working with json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "iraqi-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Structured Data\").config(\"spark.driver.memory\",\"4g\").config(\"spark.executor.memory\",\"4g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fewer-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Learning\\Python_Projects\\PySpark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frequent-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_json_df = spark.read.format(\"json\").option(\"inferSchema\", True).option(\"multiline\",True).load(\"./persons.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colonial-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|Drucy     |Poppy    |1991-02-16   |\n",
      "|Emelyne   |Blaza    |1991-11-02   |\n",
      "|Max       |Rettie   |1990-03-03   |\n",
      "|Ilario    |Kean     |1987-06-09   |\n",
      "|Toddy     |Drexel   |1992-10-28   |\n",
      "|Oswald    |Petrolli |1986-09-02   |\n",
      "|Adrian    |Clarey   |1971-08-24   |\n",
      "|Dominica  |Goodnow  |1973-08-27   |\n",
      "|Emory     |Slocomb  |1974-06-08   |\n",
      "|Jeremias  |Bode     |1997-08-02   |\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(\"first_name\",\"last_name\",\"date_of_birth\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "welsh-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- active: boolean (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extensive-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col, expr,array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressing-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------------+\n",
      "|       full_name|date_of_birth|   salary_modified|\n",
      "+----------------+-------------+------------------+\n",
      "|     Drucy Poppy|   1991-02-16|214142.24895999997|\n",
      "|   Emelyne Blaza|   1991-11-02|      903627.64816|\n",
      "|      Max Rettie|   1990-03-03|202458.74944000004|\n",
      "|     Ilario Kean|   1987-06-09|     1268328.50496|\n",
      "|    Toddy Drexel|   1992-10-28|2435294.1916900002|\n",
      "| Oswald Petrolli|   1986-09-02|132993.94329000002|\n",
      "|   Adrian Clarey|   1971-08-24|109146.07729000002|\n",
      "|Dominica Goodnow|   1973-08-27|      131735.30176|\n",
      "|   Emory Slocomb|   1974-06-08|117096.20520999999|\n",
      "|   Jeremias Bode|   1997-08-02|1205915.9116900002|\n",
      "+----------------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(concat_ws(' ',\"first_name\",\"last_name\").alias(\"full_name\"),\n",
    "                   col(\"date_of_birth\"),\n",
    "                   (col(\"salary\")*0.10*col(\"salary\")).alias(\"salary_modified\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stopped-mineral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------------+\n",
      "|       full_name|date_of_birth|   salary_modified|\n",
      "+----------------+-------------+------------------+\n",
      "|     Drucy Poppy|   1991-02-16|214142.24895999997|\n",
      "|   Emelyne Blaza|   1991-11-02|      903627.64816|\n",
      "|      Max Rettie|   1990-03-03|202458.74944000004|\n",
      "|     Ilario Kean|   1987-06-09|     1268328.50496|\n",
      "|    Toddy Drexel|   1992-10-28|2435294.1916900002|\n",
      "| Oswald Petrolli|   1986-09-02|132993.94329000002|\n",
      "|   Adrian Clarey|   1971-08-24|109146.07729000002|\n",
      "|Dominica Goodnow|   1973-08-27|      131735.30176|\n",
      "|   Emory Slocomb|   1974-06-08|117096.20520999999|\n",
      "|   Jeremias Bode|   1997-08-02|1205915.9116900002|\n",
      "+----------------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(concat_ws(' ',\"first_name\",\"last_name\").alias(\"full_name\"),\n",
    "                   col(\"date_of_birth\"),\n",
    "                   expr(\"salary*0.10*salary\").alias(\"salary_modified\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-carter",
   "metadata": {},
   "source": [
    "# Distinct, Drop duplicates, Order by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amazing-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capital-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(\"active\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proper-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(\"active\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+\n",
      "|first_name|  last_name|date_of_birth|\n",
      "+----------+-----------+-------------+\n",
      "|      Wynn|      Sayre|   1997-06-30|\n",
      "|     Deina|    Pennick|   1999-11-28|\n",
      "|    Darbee|  Brownjohn|   1996-02-07|\n",
      "|     Davin|       Labb|   1988-01-27|\n",
      "|    Kelila|Harrowsmith|   1973-01-02|\n",
      "|  Thorvald|     Finnan|   1984-09-16|\n",
      "|    Daveta|  Crutchley|   1978-11-16|\n",
      "|  Elianora|     Notman|   1999-06-26|\n",
      "|     Drucy|      Poppy|   1991-02-16|\n",
      "| Franciska|       Lees|   1982-07-15|\n",
      "+----------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(\"first_name\",\"last_name\",\"date_of_birth\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "known-choir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+\n",
      "|first_name| last_name|date_of_birth|\n",
      "+----------+----------+-------------+\n",
      "|      Wynn|     Sayre|   1997-06-30|\n",
      "|  Wolfgang|     Inger|   1973-11-16|\n",
      "|    Wilden|    Mayger|   1998-12-27|\n",
      "|    Welbie|   Crackel|   1990-10-24|\n",
      "|    Virgie|  Domanski|   2002-01-05|\n",
      "|     Trace|     Balke|   1982-01-03|\n",
      "|     Toddy|    Drexel|   1992-10-28|\n",
      "|     Toddy|Matevosian|   1972-03-17|\n",
      "|      Tish|    Machon|   1995-06-08|\n",
      "|   Timothy|    Ervine|   1971-06-02|\n",
      "|  Thorvald|    Finnan|   1984-09-16|\n",
      "|  Theodore|  Climance|   1999-01-30|\n",
      "|   Stanley| Sargeaunt|   1986-09-12|\n",
      "|       Sky|     Hails|   1971-02-19|\n",
      "|  Sherline|   Primett|   1972-07-23|\n",
      "+----------+----------+-------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.select(\"first_name\",\"last_name\",\"date_of_birth\").orderBy(\"first_name\",\"date_of_birth\", ascending=False).show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "perfect-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [(\"hey\",1,10),(\"ola\",2,20),(\"hey\",1,30),(\"hey\",1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cardiac-bahrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fallen-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = spark.createDataFrame(lst,[\"name\",\"id\",\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dominican-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "generous-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "plastic-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.select(\"name\",\"id\",\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "handy-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.select(\"name\",\"id\",\"salary\").drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decent-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.select(\"name\",\"id\",\"salary\").dropDuplicates([\"name\",\"id\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-convention",
   "metadata": {},
   "source": [
    "# ROWS AND UNIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "organic-alabama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eastern-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst = [(\"new\",4,40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "military-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst_df = spark.createDataFrame(new_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "secure-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = lst_df.union(new_lst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "induced-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "| new|  4|    40|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-scene",
   "metadata": {},
   "source": [
    "## Adding Renaming and Dropping columns in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hidden-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adaptive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_new_column_df = final_df.withColumn(\"salary_increase\", expr(\"salary * 10 * salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "radio-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+---------------+\n",
      "|name| id|salary|salary_increase|\n",
      "+----+---+------+---------------+\n",
      "| hey|  1|    10|           1000|\n",
      "| ola|  2|    20|           4000|\n",
      "| hey|  1|    30|           9000|\n",
      "| hey|  1|    10|           1000|\n",
      "| new|  4|    40|          16000|\n",
      "+----+---+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_new_column_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "smart-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name| id|salary|\n",
      "+----+---+------+\n",
      "| hey|  1|    10|\n",
      "| ola|  2|    20|\n",
      "| hey|  1|    30|\n",
      "| hey|  1|    10|\n",
      "| new|  4|    40|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_new_column_df.drop(\"salary_increase\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "unauthorized-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+---------------+\n",
      "|name| id|salaryRenamed|salary_increase|\n",
      "+----+---+-------------+---------------+\n",
      "| hey|  1|           10|           1000|\n",
      "| ola|  2|           20|           4000|\n",
      "| hey|  1|           30|           9000|\n",
      "| hey|  1|           10|           1000|\n",
      "| new|  4|           40|          16000|\n",
      "+----+---+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_new_column_df.withColumnRenamed(\"salary\",\"salaryRenamed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "greek-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "administrative-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------------+----------+---+--------------------+---------+-------+\n",
      "|active|date_of_birth|          fav_movies|first_name| id|           image_url|last_name| salary|\n",
      "+------+-------------+--------------------+----------+---+--------------------+---------+-------+\n",
      "|  true|   1991-02-16|  [I giorni contati]|     Drucy|  1|http://dummyimage...|    Poppy|1463.36|\n",
      "| false|   1991-11-02|[Musketeer, The, ...|   Emelyne|  2|http://dummyimage...|    Blaza|3006.04|\n",
      "| false|   1990-03-03|[The Forgotten Sp...|       Max|  3|http://dummyimage...|   Rettie|1422.88|\n",
      "|  true|   1987-06-09|[Up Close and Per...|    Ilario|  4|http://dummyimage...|     Kean|3561.36|\n",
      "|  true|   1992-10-28|[Walk in the Clou...|     Toddy|  5|http://dummyimage...|   Drexel|4934.87|\n",
      "| false|   1986-09-02|[Wing and the Thi...|    Oswald|  6|http://dummyimage...| Petrolli|1153.23|\n",
      "| false|   1971-08-24|[Walking Tall, Pa...|    Adrian|  7|http://dummyimage...|   Clarey|1044.73|\n",
      "| false|   1973-08-27|    [Hearts Divided]|  Dominica|  8|http://dummyimage...|  Goodnow|1147.76|\n",
      "|  true|   1974-06-08|[Snake and Crane ...|     Emory|  9|http://dummyimage...|  Slocomb|1082.11|\n",
      "|  true|   1997-08-02|[Farewell to Arms...|  Jeremias| 10|http://dummyimage...|     Bode|3472.63|\n",
      "+------+-------------+--------------------+----------+---+--------------------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "macro-anatomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- active: boolean (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hungry-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "racial-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_timestamp_df = read_json_df.withColumn(\"processed_date_time\", to_utc_timestamp(current_timestamp(),\"IST\")).select(\"active\", \"date_of_birth\",\"processed_date_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "polyphonic-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- active: boolean (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- processed_date_time: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_timestamp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "collect-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-----------------------+\n",
      "|active|date_of_birth|processed_date_time    |\n",
      "+------+-------------+-----------------------+\n",
      "|true  |1991-02-16   |2021-05-13 10:39:17.226|\n",
      "|false |1991-11-02   |2021-05-13 10:39:17.226|\n",
      "|false |1990-03-03   |2021-05-13 10:39:17.226|\n",
      "|true  |1987-06-09   |2021-05-13 10:39:17.226|\n",
      "|true  |1992-10-28   |2021-05-13 10:39:17.226|\n",
      "|false |1986-09-02   |2021-05-13 10:39:17.226|\n",
      "|false |1971-08-24   |2021-05-13 10:39:17.226|\n",
      "|false |1973-08-27   |2021-05-13 10:39:17.226|\n",
      "|true  |1974-06-08   |2021-05-13 10:39:17.226|\n",
      "|true  |1997-08-02   |2021-05-13 10:39:17.226|\n",
      "|false |1971-06-02   |2021-05-13 10:39:17.226|\n",
      "|false |1981-12-17   |2021-05-13 10:39:17.226|\n",
      "|false |1996-03-07   |2021-05-13 10:39:17.226|\n",
      "|true  |1989-07-20   |2021-05-13 10:39:17.226|\n",
      "|false |2000-10-07   |2021-05-13 10:39:17.226|\n",
      "|true  |1988-07-29   |2021-05-13 10:39:17.226|\n",
      "|false |1974-07-20   |2021-05-13 10:39:17.226|\n",
      "|true  |1989-06-21   |2021-05-13 10:39:17.226|\n",
      "|false |1998-11-03   |2021-05-13 10:39:17.226|\n",
      "|false |1979-05-06   |2021-05-13 10:39:17.226|\n",
      "+------+-------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_timestamp_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-greeting",
   "metadata": {},
   "source": [
    "# WORKING WITH MISSING OR BAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bright-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "bad_movies_list = [Row(None, None, None),\n",
    "                   Row(None, None, 2020),\n",
    "                   Row(\"John Doe\", \"Awesome Movie\", None),\n",
    "                   Row(None, \"Awesome Movie\", 2021),\n",
    "                   Row(\"Mary Jane\", None, 2019),\n",
    "                   Row(\"Vikter Duplaix\", \"Not another teen movie\", 2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "parliamentary-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_columns = [\"movie-name\",\"review\",\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "separate-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_df = spark.createDataFrame(bad_movies_list,bad_movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "demanding-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|    movie-name|              review|year|\n",
      "+--------------+--------------------+----+\n",
      "|          null|                null|null|\n",
      "|          null|                null|2020|\n",
      "|      John Doe|       Awesome Movie|null|\n",
      "|          null|       Awesome Movie|2021|\n",
      "|     Mary Jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "vertical-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|    movie-name|              review|year|\n",
      "+--------------+--------------------+----+\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drops rows which has atleast one value in a column \n",
    "bad_movies_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dynamic-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|    movie-name|              review|year|\n",
      "+--------------+--------------------+----+\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drops rows which has atleast one value in a column \n",
    "bad_movies_df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "handed-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|    movie-name|              review|year|\n",
      "+--------------+--------------------+----+\n",
      "|          null|                null|2020|\n",
      "|      John Doe|       Awesome Movie|null|\n",
      "|          null|       Awesome Movie|2021|\n",
      "|     Mary Jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drops rows which has imall null value in a column \n",
    "bad_movies_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "roman-neutral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|    movie-name|              review|year|\n",
      "+--------------+--------------------+----+\n",
      "|      John Doe|       Awesome Movie|null|\n",
      "|     Mary Jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"movie-name\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "peaceful-geneva",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|movie-name|review|year|\n",
      "+----------+------+----+\n",
      "|      null|  null|null|\n",
      "|      null|  null|2020|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"movie-name\").isNull()).filter(col(\"review\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-cruise",
   "metadata": {},
   "source": [
    "# Working with User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "talented-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bacterial-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_lst = [(\"Ram\",90),\n",
    "          (\"Sai\",20),\n",
    "          (\"Karthik\",50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "processed-sociology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(student_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "settled-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_lst_columns = [\"name\",\"marks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "alone-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = spark.createDataFrame(student_lst, student_lst_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "reflected-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|marks|\n",
      "+-------+-----+\n",
      "|    Ram|   90|\n",
      "|    Sai|   20|\n",
      "|Karthik|   50|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "brazilian-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grades(marks:int):\n",
    "    if marks>100:\n",
    "        print(\"Cheating\")\n",
    "        grade = \"F\"\n",
    "    elif marks>=80:\n",
    "        grade = \"A\"\n",
    "    elif marks>=30:\n",
    "        grade = \"B\"\n",
    "    else:\n",
    "        grade = \"F\"\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "coordinate-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesUDF = udf(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "powerful-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|   name|marks|grade|\n",
      "+-------+-----+-----+\n",
      "|    Ram|   90|    A|\n",
      "|    Sai|   20|    F|\n",
      "|Karthik|   50|    B|\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.withColumn(\"grade\",gradesUDF(col(\"marks\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "public-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Learning\\Python_Projects\\PySpark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "intense-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"D:\\Downloads_HpOmen\\sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-journalist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sound-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath_df = spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\", True).load(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "failing-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |--  address: string (nullable = true)\n",
      " |--  id: double (nullable = true)\n",
      " |--  inIndia: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "colonial-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---+--------+\n",
      "|   name|    address| id| inIndia|\n",
      "+-------+-----------+---+--------+\n",
      "|    ram| kukatpally|1.0|    true|\n",
      "|    sai|       kphb|2.0|   false|\n",
      "|karthik|   ameerpet|3.0|    true|\n",
      "+-------+-----------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "advance-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "changeSchema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"id\", DoubleType(), True),\n",
    "    StructField(\"inIndia\", BooleanType(), True),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dedicated-ferry",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-4d4e96b3a3ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfileData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: read() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
